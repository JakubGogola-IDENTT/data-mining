{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from string import punctuation\n",
    "from itertools import groupby\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/stopwords.txt', encoding='UTF-8') as f:\n",
    "    stopwords = [word for line in f for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(words, stopwords):\n",
    "    filtered_words = [word.lower().translate(str.maketrans('','', punctuation)) for word in words]\n",
    "    filtered_words = [word for word in filtered_words if word not in stopwords] # add stemming\n",
    "    return filtered_words\n",
    "\n",
    "def count_words(words):\n",
    "    def add_to_dict(acc, word):\n",
    "        if word not in acc or not word:\n",
    "            acc[word] = 1\n",
    "        else:\n",
    "            acc[word] += 1\n",
    "\n",
    "        return acc\n",
    "\n",
    "    words_count = reduce(lambda acc, word: add_to_dict(acc, word), words, {})\n",
    "    words_count = [(word, count) for word, count in words_count.items()]\n",
    "    words_count.sort(key=(lambda pair: pair[1]), reverse=True)\n",
    "    \n",
    "    return words_count \n",
    "\n",
    "def to_csv(file_dir, words_count):\n",
    "    with open(file_dir, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for word, count in words_count:\n",
    "            writer.writerow([count, word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/cobc.txt', encoding='UTF-8') as f:\n",
    "    words = [word for line in f for word in line.split()]\n",
    "\n",
    "filtered_words = process_words(words, stopwords)\n",
    "words_count = count_words(filtered_words)\n",
    "to_csv('data/results.csv', words_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/cobc.txt', encoding='UTF-8') as f:\n",
    "    chapters = []\n",
    "    for key, group in groupby(f, lambda line: line.startswith('Chapter')):\n",
    "        if not key:\n",
    "            group = list(group)\n",
    "            chapter = [word for line in group for word in line.split()]\n",
    "            chapters.append(chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['juniper',\n",
       " 'men',\n",
       " 'born',\n",
       " 'condemned',\n",
       " 'wise',\n",
       " 'say',\n",
       " 'suckle',\n",
       " 'breast',\n",
       " 'death',\n",
       " 'bow',\n",
       " 'silent',\n",
       " 'monarch',\n",
       " 'lord',\n",
       " 'shadow',\n",
       " 'lifts',\n",
       " 'finger',\n",
       " 'feather',\n",
       " 'flutters',\n",
       " 'earth',\n",
       " 'reason',\n",
       " 'song',\n",
       " 'good',\n",
       " 'go',\n",
       " 'young',\n",
       " 'wicked',\n",
       " 'prosper',\n",
       " 'king',\n",
       " 'chaos',\n",
       " 'lords',\n",
       " 'breath',\n",
       " 'stills',\n",
       " 'souls',\n",
       " 'found',\n",
       " 'city',\n",
       " 'dedicated',\n",
       " 'worship',\n",
       " 'long',\n",
       " 'ago',\n",
       " 'old',\n",
       " 'lost',\n",
       " 'dedication',\n",
       " 'dark',\n",
       " 'majesty',\n",
       " 'godhead',\n",
       " 'frayed',\n",
       " 'forgotten',\n",
       " 'stand',\n",
       " 'shadow',\n",
       " 'juniper',\n",
       " 'faced',\n",
       " 'immediate',\n",
       " 'fear',\n",
       " 'specter',\n",
       " 'yesteryear',\n",
       " 'leaking',\n",
       " 'present',\n",
       " 'upon',\n",
       " 'height',\n",
       " 'overlooking',\n",
       " 'city',\n",
       " 'black',\n",
       " 'company',\n",
       " 'went',\n",
       " 'strange',\n",
       " 'city',\n",
       " 'far',\n",
       " 'beyond',\n",
       " 'bounds',\n",
       " 'ladys',\n",
       " 'empire',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'beginning',\n",
       " 'beginning',\n",
       " 'far',\n",
       " 'away',\n",
       " 'two',\n",
       " 'old',\n",
       " 'friends',\n",
       " 'handful',\n",
       " 'men',\n",
       " 'would',\n",
       " 'meet',\n",
       " 'later',\n",
       " 'stood',\n",
       " 'nosetonose',\n",
       " 'shadow']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters = [process_words(chapter, stopwords) for chapter in chapters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
